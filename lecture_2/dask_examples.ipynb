{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line\n",
    "\n",
    "\n",
    "This is the most fundamental way to deploy Dask on multiple machines. In production environments, this process is often automated by some other resource manager. Hence, it is rare that people need to follow these instructions explicitly. But since we want learn how to \"build\" a cluster we want study how to start it from the command line.\n",
    "\n",
    "A ```dask.distributed``` network consists of one ```dask-scheduler``` process and several ```dask-worker``` processes that connect to that scheduler. These are normal Python processes that can be executed from the command line. We launch the dask-scheduler executable in one process and the dask-worker executable in several processes, possibly on different machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, respect to the revious lectures, today we want to create a cluster \"from scratch\" using IP addresses and real workers and not the automatic \"local cluster\" created by dask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first let's see how works the ```dask-scheduler``` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dask-scheduler --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "#dask-scheduler run it inside a real bash terminal not from jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command ```dask-worker``` on the rest of the nodes. Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dask-worker --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thisn command must be run by providing the address to the node that hosts ```dask-scheduler```:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#dask-worker 192.168.1.12:8687 run int inside the real command line not from jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic concepts\n",
    "The scheduler and workers both need to accept TCP connections on an open port. By default, the scheduler binds to port 8786 and the worker binds to a random open port. If you are behind a firewall then you may have to open particular ports or tell Dask on a different port.\n",
    "\n",
    "Dask workers are run within a *nanny* process that *monitors* the worker process and restarts it if necessary.\n",
    "\n",
    "As we have saw last lecture, Dask schedulers and even workers host interactive diagnostic web servers using the Bokeh server. These are optional, but generally useful to users. The diagnostic server on the scheduler is particularly valuable, and is served on port 8787."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to create a your first cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first run the cell below in order to indentify your network-card and what your IP is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "ifconfig ##only for those of you that does not use the docker cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open you command line and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask-scheduler --host IP --port 8786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point open another command line and run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask-worker IP:8786 --nprocs 2 #this command create 2 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when is all up to date try to connect to the dashboard and take a look to your new cluster!\n",
    "If you have install all the packages in the correct way you should be able to access to the dashboard at: IP:8787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an old exercise over the new cluster\n",
    "\n",
    "Try to count how many words are present in all the documents over the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n",
    "categories = [\n",
    "     'comp.graphics',\n",
    "     'comp.os.ms-windows.misc',\n",
    "     'comp.sys.ibm.pc.hardware',\n",
    "     'comp.sys.mac.hardware',\n",
    "     'comp.windows.x',\n",
    "     'misc.forsale',\n",
    "     'rec.autos',\n",
    "     'rec.motorcycles',\n",
    "     'rec.sport.baseball',\n",
    "     'rec.sport.hockey',\n",
    "     'sci.crypt',\n",
    "     'sci.electronics',\n",
    "     'sci.med',\n",
    "     'sci.space'\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='train', categories=categories ).data\n",
    "\n",
    "print(\"Texts document present on the dataset: \"+str(len(dataset)))\n",
    "\n",
    "def count_word_in_statement(text):\n",
    "    \"\"\"\n",
    "    This function takes a text as input and return the number of the words that it contains\n",
    "    \"\"\"\n",
    "    #time.sleep(0.1)\n",
    "    splitted_words = text.split()\n",
    "    return len(splitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "total_words_in_all_data = 0\n",
    "for index in range(0, len(dataset)):\n",
    "    total_words_in_all_data = total_words_in_all_data + count_word_in_statement(dataset[index])\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('dask-scheduler:8786') #change your setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#futures = client.map(count_word_in_statement, dataset)\n",
    "futures = [client.submit(count_word_in_statement, data) for data in dataset]\n",
    "\n",
    "futures = client.submit(sum, futures)\n",
    "total_words_in_all_data = client.gather(futures)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why in this case sequential code took more than 10 times les than ditributed version?\n",
    "\n",
    "In general when yuo have to deal with a cluster you have to think about the *overhead* You can image the overhead like the the computational time necessary process your data. \n",
    "Typically in a cluster there two kind of overhead:\n",
    "+ scheduler overhead in serializing the objects that must be sent to workers\n",
    "+ connection overhead. The speed of the network connection between the cluster nodes\n",
    "\n",
    "In the first case, the scheduler adds about one millisecond of overhead per task or Future object. Despite this may sound fast or inconsequential, it's quite slow if you run a large number of tasks. Under this perspective, a larger number of the task means a larger amount of time to create the Future objects of the tasks. \n",
    "In the light of above, if your functions run faster than 100ms or so then you might not see any\n",
    "speedup from using distributed computing, but even worse, probably you might see that the performances get worse.\n",
    "\n",
    "In the second case things are different. The connection overhead may depends from several factors including the stability of the network, the type (wired or WiFi or optic fibe), and bandwith of the network.\n",
    "\n",
    "This is what is happening in the previous example.\n",
    "\n",
    "Let's try to introduce a simulation of intesive computation (a sleep of 10ms: 10 times less the the overhead generated by dask-scheduler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_in_statement(text):\n",
    "    \"\"\"\n",
    "    This function takes a text as input and return the number of the words that it contains\n",
    "    \"\"\"\n",
    "    splitted_words = text.split()\n",
    "    time.sleep(0.01)\n",
    "    return len(splitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run and wait the sequantial code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "total_words_in_all_data = 0\n",
    "for index in range(0, len(dataset)):\n",
    "    total_words_in_all_data = total_words_in_all_data + count_word_in_statement(dataset[index])\n",
    "    end = time.time() - start\n",
    "    if end >= 50:\n",
    "        print(\"More than {}s of computation time...\".format(end))\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('dask-scheduler:8786') #change your setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "futures = [client.submit(count_word_in_statement, data) for data in dataset]\n",
    "futures = client.submit(sum, futures)\n",
    "total_words_in_all_data = client.gather(futures)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increment the number of workers or threads per worker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel like a hero and you don't be afraid to become old by standing in front of the PC, you can try to compare the sequential code and the distributed code by increasing the sleep time 100ms or 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How works the distribution and the scheduling of the processes?\n",
    "\n",
    "#### How a worker is choosen?\n",
    "Even though you can reduce and make some restrictions, e.g: restriction over worker resources, Dask automatically decides the suitable workers for your tasks by figuring out the optimized worker for each task.\n",
    "This means that, if a task has significant data dependencies or if the workers are under heavy load then this choice of worker can strongly impact global performance because the decision becomes heavy.\n",
    "\n",
    "Dask follows the following rules before to assign a task to a worker:\n",
    "+ If the task has no major dependencies and no restrictions then we find the least occupied worker.\n",
    "\n",
    "+ if a task has user-provided restrictions (for example it must run on a machine with a GPU) then we restrict the available pool of workers to just that set, otherwise, we consider all workers\n",
    "+ from the pool of workers Dask determinates the workers to whom the least amount of data would need to be transferred (means less overhead on the cluster and hence computation optimization).\n",
    "+  if some dependencies in the graph can be broken the will be assigned to the worker that currently has the fewest tasks.\n",
    "\n",
    "\n",
    "Dask also allows modifying the worker decision function in order to be more flexible and to improve the customization of a cluster. This means that particular processes or particular computational fields in which performances can be improved by customizing and optimizing the task's assignation decision can be made more performant.\n",
    "\n",
    "Breaking the dependencies in some cases is necessary, especially if each node has a lot of sons. In this case, each node with his sons must be removed from the graph and computed alone. This has a huge impact on performances and memory. On the other hand, this means that when a user submits a task, the computation graph must be scan to figuring out and optimizing this kind of dependencies.\n",
    "\n",
    "\n",
    "#### How choose the next task?\n",
    "Typically Dask follows those rules in order to choose the next task that must be executed:\n",
    "+ Run tasks on a first-come-first-served basis for fairness between multiple clients\n",
    "+ Run tasks that are part of the critical path in an effort to reduce total running time and minimize straggler workloads\n",
    "+ Run tasks that allow us to release many dependencies in an effort to keep the memory footprint small\n",
    "+ Run tasks that are related so that large chunks of work can be completely eliminated before running new chunks of work\n",
    "\n",
    "As you can see a part of the overhead on a cluster is principally caused by the optimization of the execution task decision. Even though these are rules implemented by Dask, in general, the majority of the Cluster, even if they are based on other frameworks and other architectures, follow the same similar approaches.\n",
    "\n",
    "On the other hand, some computational fields may require a different approach to decide which tasks can be executed, e.g: by using last-in-first-out approach or by giving a priority to each task in order to execute first some processes.\n",
    "\n",
    "In some cases, Dask optimization exploit also a partially last-in-first-out approach. When a worker finishes a task the immediate dependencies of that task get top priority. This encourages a behavior of finishing ongoing work immediately before starting new work. This often conflicts with the first-come-first-served objective but often results in shorter total runtimes and significantly reduced memory footprints.\n",
    "\n",
    "\n",
    "#### Where these decisions are made?\n",
    "\n",
    "The decision are basically made ina small steps and in a different computation steps by client, scheduler, and workers:\n",
    "\n",
    "+ As we submit a graph from the *client* to the scheduler we automatically assign a numeric priority to each task of that graph. This priority focuses on computing deeply before broadly, preferring critical paths, and preferring nodes with many dependencies.\n",
    "\n",
    "+ When the graph reaches the scheduler the scheduler changes each of these numeric priorities into a tuple of two numbers, the first of which is an increasing counter, the second of which is the client-generated priority described above. This per-graph counter encourages a first-in-first-out policy between computations. All tasks from a previous call to compute have a higher priority than all tasks from a subsequent call to compute (or submit, persist, map, or any operation that generates futures).\n",
    "\n",
    "+ Whenever a task is ready to run the scheduler assigns it to a worker. The scheduler does not wait based on priority. However when the worker receives these tasks it considers their priorities when determining which tasks to prioritize for communication or for computation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Resources\n",
    "\n",
    "Let's suppose that you want to run a proces over a cluster, but only in those machine that has a GPU or have at least 16Gb of RAM. Now let's imagin that you have a cluster of ten computers in which four have a GPU while the others no. In this case we want to balance tasks across the cluster with these resource constraints in mind, allocating GPU-constrained tasks to GPU-enabled workers. Additionally we need to be sure to constrain the number of GPU tasks that run concurrently on any given worker to ensure that we respect the provided limits.\n",
    "Clearly, this situation arises not only for GPUs but for many resources like tasks that require a large amount of memory at runtime, special disk access, or access to special hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you require workers with particular resources you must be sure that those resources are availables over the cluster.\n",
    "Otherwise your processes should be never executed.\n",
    "\n",
    "Let's try an example togheter: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, stop the workers that you have in your cluster and the scheduler. Start again the scheduler and then turn up two workers with those commands:\n",
    "\n",
    "+ ```dask-worker dask-scheduler:8786 --nprocs 1 --nthreads 1 --resources \"GPU=2\"```\n",
    "+ ```dask-worker dask-scheduler:8786 --nprocs 1 --nthreads 1 --resources \"GPU=1\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "client = Client('dask-scheduler:8786') ##change your settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = []\n",
    "\n",
    "for i in range(100):\n",
    "    matrices.append(np.random.rand(4,3))\n",
    "\n",
    "def compute_polynomial_kernel(matrix):\n",
    "    polynomial_degree = 2\n",
    "    return np.power((np.dot(matrix, matrix.T)+1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on a matrix computation let's suppose that we want exploit the multi-gpu available only on some workers. \n",
    "Assume that we need to use 3 GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = [client.submit(compute_polynomial_kernel, matrix, resources={'GPU': 3}) for matrix in matrices]\n",
    "\n",
    "kernels = client.gather(processed)\n",
    "\n",
    "for i in kernels:\n",
    "    print(\"Kernel is: {}\".format(i))\n",
    "    print()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing is happening but the code still running...... Let's try to add on-the-fly a worker with 3 GPUs\n",
    "\n",
    "```dask-worker 192.168.1.12:8786 --nprocs 1 --nthreads 1 --resources \"GPU=3\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Compute the traces of all the generated matrix. Execute this code over 2 workers with 2 \"SpecialCPU\" each one.\n",
    "You must use the ```map``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [np.random.randint(low=m, high=m+1, size=(4, 3)) for m in (range(11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Clien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Execute the code of the \"howmany_within_range\" exercise from the previous lecture, into a worker with 256Gb of RAM. Map function is not allowed.\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
